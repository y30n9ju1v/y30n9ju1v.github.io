+++
title = 'DeepXplore 2'
date = 2024-07-14T10:05:38+09:00
draft = false
+++

이 글은 DeepXplore: Automated Whitebox Testing of Deep Learning Systems (https://arxiv.org/abs/1705.06640)을 번역 및 요약한 글입니다.
[DeepXplore 1]({{< ref "DeepXplore-1" >}}) 에서 이어집니다.

## 4. Methodology
이 섹션에서는 우리의 알고리즘에 대한 상세한 기술 설명을 제공합니다.
먼저, DNN을 위한 뉴런 커버리지와 그래디언트의 개념을 정의하고 설명합니다.
다음으로, 테스트 문제를 공동 최적화 문제로 어떻게 공식화할 수 있는지 설명합니다.
마지막으로, 공동 최적화 문제를 해결하기 위한 그래디언트 기반 알고리즘을 제공합니다.

### 4.1 Definitions
**Neuron coverage**
우리는 테스트 입력 세트의 뉴런 커버리지를 모든 테스트 입력에 대해 활성화된 고유한 뉴런의 수와 DNN의 전체 뉴런 수의 비율로 정의합니다.
뉴런의 출력이 임계값(예: 0)보다 높으면 그 뉴런이 활성화된 것으로 간주합니다.

더 형식적으로, 모든 뉴런이 집합 \(N = \{n\relax{1}, n\relax{2}, ...\}\) 으로 표현되고, 모든 테스트 입력이 집합 \(T = \{x\relax{1}, x\relax{2}, ...\}\) 으로 표현된다고 가정합시다.
여기서 \(out(n, x)\)은 주어진 테스트 입력 \(x\)에 대해 DNN의 뉴런 \(n\)의 출력 값을 반환하는 함수입니다.
여기서 굵게 표시된 \(x\)는 \(x\)가 벡터임을 나타냅니다.
뉴런이 활성화되었다고 간주하는 임계값을 \(t\) 로 나타냅시다.
이 설정에서 뉴런 커버리지는 다음과 같이 정의할 수 있습니다.

\[NCov(T, x) = \frac{\left| \{n \mid \forall x \in T, out(n, x) > t\} \right|}{\left| N \right|}\]

실제로 뉴런 커버리지가 어떻게 계산되는지 보여주기 위해, 그림 4b에 표시된 DNN을 고려해 봅시다.
그림 4b에 나와 있는 빨간색 자동차 입력 이미지에 대한 뉴런 커버리지(임계값 0)는 5/8 = 0.625가 될 것입니다.

![Figure 4](/posts/paper/DeepXplore/figure4.png)

**Gradient**
DNN의 뉴런 출력에 대한 입력의 그래디언트 또는 전진 도함수는 딥 러닝 문헌에서 잘 알려져 있습니다.
이들은 적대적 예제를 만들기 위해 [26, 29, 52, 72] 그리고 DNN을 시각화하고 이해하기 위해 [44, 65, 87] 광범위하게 사용되어 왔습니다.
여기서는 완전성을 위해 간단히 정의를 제공하며, 더 자세한 내용을 알고 싶은 독자들은 [87]을 참고하시기 바랍니다.

\(θ\)와 \(x\)가 각각 DNN의 파라미터와 테스트 입력을 나타낸다고 합시다.
뉴런이 수행하는 파라미터 함수는 \(y = f(θ, x)\)로 표현될 수 있으며, 여기서 \(f\)는 \(θ\)와 \(x\)를 입력으로 받아 \(y\)를 출력하는 함수입니다.
\(y\)는 DNN에 정의된 어떤 뉴런의 출력일 수 있습니다(예: 출력층의 뉴런 또는 중간층의 뉴런).
입력 \(x\)에 대한 \(f(θ, x)\)의 그래디언트는 다음과 같이 정의될 수 있습니다:

\[G = \nabla_{x} f(\theta, x) = \frac{\partial y}{\partial x}          \qquad\qquad(1)\]

\(f\) 내부의 계산은 본질적으로 이전 층의 입력을 계산하고 다음 층으로 출력을 전달하는 함수들의 연속입니다.
따라서 \(G\)는 미적분학의 연쇄 법칙을 사용하여 계산할 수 있습니다.
즉, \(y\)를 출력하는 뉴런의 층에서 시작하여 \(x\)를 입력으로 받는 입력 층에 도달할 때까지 층별 도함수를 계산함으로써 얻을 수 있습니다.
그래디언트 \(G\)의 차원은 입력 \(x\)의 차원과 동일하다는 점을 유의하세요.

### 4.2 DeepXplore algorithm
앞서 §3에서 논의한 바와 같이, 테스트 생성 과정의 목표는 사용자에 의해 제공된 도메인별 제약 조건을 유지하면서 관찰된 차별적 동작의 수와 뉴런 커버리지를 모두 극대화하는 것입니다.
알고리즘 1은 이 공동 최적화 문제를 해결하여 테스트 입력을 생성하는 알고리즘을 보여줍니다.

**Maximizing differential behaviors**
최적화 문제의 첫 번째 목표는 테스트된 DNN에서 서로 다른 동작을 유도할 수 있는 테스트 입력을 생성하는 것입니다.
즉, 서로 다른 DNN이 동일한 입력을 서로 다른 클래스로 분류하게 하는 것입니다.
n개의 DNN \(F_{k \in 1..n} : \mathbf{x} \rightarrow \mathbf{y}\) 가 있다고 가정합시다.
여기서 \(F_k\)는 k번째 신경망이 모델링한 함수입니다.
\(x\)는 입력을 나타내고 \(y\)는 출력 클래스 확률 벡터를 나타냅니다.
모든 DNN이 동일한 클래스로 분류하는 임의의 시드 \(x\)가 주어졌을 때, 우리의 목표는 수정된 입력 \(x'\)가 적어도 하나의 DNN에 의해 다르게 분류되도록 \(x\)를 수정하는 것입니다.

\(F_k(x)[c]\)가 \(F_k\)가 \(x\)를 \(c\)로 예측하는 클래스 확률이라고 합시다. 우리는 임의로 하나의 신경망 \(F_j\)를 선택하고(알고리즘 1의 6번째 줄) 다음 목적 함수를 최대화합니다:

\[obj_1(\mathbf{x}) = \sum_{k \neq j} F_{k}(\mathbf{x})[c] - \lambda_{1} \cdot F_{j}(\mathbf{x})[c] \qquad\qquad(2)\]

여기에서 \(\lambda_1\)은 DNN \(F_{k \neq j}\)가 이전과 동일한 클래스 출력을 유지하는 목표 항목과 DNN \(F_j\)가 다른 클래스 출력을 생성하는 목표 항목 간의 균형을 맞추기 위한 매개변수입니다.
\(F_{k ∈ 1..n}\)이 모두 미분 가능하므로, 식 2는 계산된 기울기\(\frac{\partial obj_1(\mathbf{x})}{\partial \mathbf{x}}\)를 기반으로 \(x\)를 반복적으로 변경하여 (Algorithm 1의 8-14행과 COMPUTE_OBJ1 절차) 기울기 상승을 사용하여 쉽게 최대화할 수 있습니다.

**Maximizing neuron coverage**
두 번째 목표는 뉴런 커버리지를 극대화하는 입력을 생성하는 것입니다.
우리는 비활성화된 뉴런을 반복적으로 선택하고, 해당 뉴런의 출력이 뉴런 활성화 임계값을 초과하도록 입력을 수정함으로써 이 목표를 달성합니다.
뉴런 \(n\)의 출력을 극대화하려고 한다고 가정해 봅시다.
즉, \(obj_2(x) = f_n(x)\)을 최대화하여 \(f_n(x) > t\)가 되도록 하는 것입니다.
여기서 \(t\)는 뉴런 활성화 임계값이고, \(f_n(x)\)는 \(x\) (DNN의 원래 입력)를 입력으로 받아 뉴런 \(n\)의 출력을 생성하는 함수입니다 (Equation 1에서 정의됨).
\(f_n(x)\)는 그래디언트\(\frac{\partial f_{n}(\mathbf{x})}{\partial \mathbf{x}}\)가 존재하는 미분 가능한 함수이므로, 우리는 다시 그래디언트 상승 메커니즘을 활용할 수 있습니다.

여러 뉴런을 동시에 공동으로 최대화할 수도 있지만, 명확성을 위해 이 알고리즘에서는 한 번에 하나의 뉴런을 활성화하도록 선택합니다(알고리즘 1의 8-14번째 줄 및 COMPUTE_OBJ2 절차).

**Joint optimization**
우리는 위에서 설명한 \(obj_1\)과 \(f_n\)을 공동으로 최대화하며, 다음 함수를 최대화합니다:

\[obj_{joint} = \left(\sum_{i \neq j} F_{i}(\mathbf{x})[c] - \lambda_{1} F_{j}(\mathbf{x})[c] \right) + \lambda_{2} \cdot f_{n}(\mathbf{x}) \qquad\qquad(3)\]

여기서 \(\lambda_2\)는 공동 최적화 과정의 두 목표 사이의 균형을 맞추기 위한 매개변수이며, \(n\)은 각 반복에서 무작위로 선택한 비활성화된 뉴런입니다(알고리즘 1의 33번째 줄).
\(obj_{joint}\)의 모든 항은 미분 가능하므로, \(x\)를 수정하여 그래디언트 상승을 사용해 공동으로 최대화할 수 있습니다(알고리즘 1의 14번째 줄).

**Domain-specific constraints**
최적화 과정에서 중요한 측면 중 하나는 생성된 테스트 입력이 물리적으로 현실적인 여러 도메인별 제약 조건을 만족해야 한다는 것입니다 [63].
예를 들어, 생성된 테스트 이미지 \( x \)의 경우 픽셀 값이 특정 범위(예: 0에서 255) 내에 있어야 합니다.

일부 제약 조건은 서포트 벡터 머신에서 사용되는 라그랑주 승수법을 사용하여 공동 최적화 과정에 효율적으로 통합될 수 있지만 [76], 대부분의 제약 조건은 최적화 알고리즘에 의해 쉽게 처리될 수 없다는 것을 발견했습니다.
따라서 생성된 테스트가 사용자 정의 도메인별 제약 조건을 충족하도록 보장하는 간단한 규칙 기반 방법을 설계했습니다.
시드 입력 \( x_{seed} = x_0 \)는 정의상 항상 제약 조건을 만족하므로, 우리의 기법은 그래디언트 상승의 i번째 반복 후에도 \( x_i \)가 여전히 제약 조건을 만족하는지 확인해야 합니다(i > 0).
우리의 알고리즘은 그래디언트를 수정하여 이 속성을 보장합니다(알고리즘 1의 13번째 줄).
따라서 \( x_{i+1} = x_i + s \cdot \text{grad} \)가 여전히 제약 조건을 만족하게 합니다(s는 그래디언트 상승의 스텝 크기입니다).

**Hyperparameters in Algorithm 1**
요약하자면, DeepXplore의 다양한 측면을 제어하는 네 가지 주요 하이퍼파라미터가 있습니다.
(1) \( \lambda_1 \)는 특정 라벨에 대한 하나의 DNN 예측을 최소화하고 나머지 DNN의 동일 라벨에 대한 예측을 최대화하는 목표 사이의 균형을 맞춥니다.
\( \lambda_1 \)가 클수록 특정 DNN의 예측 값/신뢰도를 낮추는 데 우선순위를 두고, \( \lambda_1 \)가 작을수록 다른 DNN의 예측을 유지하는 데 더 많은 비중을 둡니다.
(2) \( \lambda_2 \)는 차별적 동작 찾기와 뉴런 커버리지 사이의 균형을 제공합니다.
\( \lambda_2 \)가 클수록 다양한 뉴런을 커버하는 데 더 중점을 두고, \( \lambda_2 \)가 작을수록 더 많은 차이 유발 테스트 입력을 생성합니다.
(3) \( s \)는 반복적인 그래디언트 상승 동안 사용되는 스텝 크기를 제어합니다.
\( s \)가 클수록 지역 최적점 주변에서 진동할 수 있으며, \( s \)가 작을수록 목표에 도달하는 데 더 많은 반복이 필요할 수 있습니다.
(4) \( t \)는 각 개별 뉴런이 활성화되었는지 여부를 결정하는 임계값입니다.
\( t \)가 증가할수록 뉴런을 활성화하는 입력을 찾는 것이 점점 더 어려워집니다.

![Algorithm 1](/posts/paper/DeepXplore/algorithm1.png)

## 5. Implementation
우리는 TensorFlow 1.0.1과 Keras 2.0.3 DL 프레임워크를 사용하여 DeepXplore를 구현했습니다.
우리의 코드는 TensorFlow/Keras를 기반으로 하지만, 이러한 프레임워크에 대한 수정은 필요하지 않습니다.
우리는 공동 최적화 과정에서 TensorFlow의 효율적인 그래디언트 계산 구현을 활용합니다.
TensorFlow는 또한 임의의 뉴런 출력을 서브-DNN의 출력으로 표시하면서 입력을 원래 DNN의 입력과 동일하게 유지하여 서브-DNN을 생성하는 것을 지원합니다.
우리는 이 기능을 사용하여 DNN의 중간 계층에서 뉴런의 출력을 가로채고 기록하며, DNN의 입력에 대한 해당 그래디언트를 계산합니다.

## 6. Experimental Setup
### 6.1 Test datasets and DNNs

우리는 서로 다른 유형의 데이터를 가진 다섯 개의 인기 있는 공개 데이터셋—MNIST, ImageNet, Driving, Contagio/VirusTotal, Drebin—을 채택하고, 각 데이터셋에 대해 세 개의 DNN에서 DeepXplore를 평가합니다(즉, 총 15개의 DNN).
다섯 개의 데이터셋과 해당 DNN에 대한 요약은 표 1에 제공됩니다.
각 데이터셋에 대해, 우리는 표 1에 설명된 대로 서로 다른 아키텍처를 가진 세 개의 DNN을 테스트하기 위해 DeepXplore를 사용했습니다.

![Table 1](/posts/paper/DeepXplore/table1.png)

**MNIST**
28x28 픽셀 이미지와 0부터 9까지의 클래스 라벨을 포함한 대규모 손글씨 숫자 데이터셋입니다.
우리는 Lecun 등 [40]을 따라 LeNet 계열 [40]을 기반으로 한 세 개의 다른 신경망, 즉 LeNet-1, LeNet-4, LeNet-5를 구성합니다.

**ImageNet**
10,000,000개 이상의 수작업으로 주석이 달린 이미지를 포함한 대규모 이미지 데이터셋으로, 크라우드소싱으로 수집되고 수작업으로 라벨링되었습니다.
우리는 세 개의 잘 알려진 사전 훈련된 DNN을 테스트합니다: VGG-16 [66], VGG-19 [66], ResNet50 [31].

**Driving**
Udacity 자율 주행 자동차 챌린지 데이터셋으로, 주행 중인 자동차의 앞 유리에 장착된 카메라로 촬영한 이미지와 각 이미지에 대해 인간 운전자가 적용한 스티어링 휠 각도를 포함합니다.

**Contagio/VirusTotal**
다양한 정상 및 악성 PDF 문서를 포함하는 데이터셋입니다.
우리는 Contagio 데이터베이스에서 가져온 5,000개의 정상 PDF 문서와 12,205개의 악성 PDF 문서를 훈련 세트로 사용하고, VirusTotal [77]에서 수집한 5,000개의 악성 PDF와 Google에서 크롤링한 5,000개의 정상 PDF를 테스트 세트로 사용합니다.
따라서, 우리는 PDF 악성 코드 탐지를 위한 온라인 서비스인 PDFrate [54, 68]에서 135개의 정적 특징을 사용하여 세 가지 다른 DNN을 정의하고 훈련합니다.
구체적으로, 우리는 하나의 입력층, 하나의 소프트맥스 출력층, 그리고 N개의 200개 뉴런이 있는 완전 연결 은닉층으로 구성된 신경망을 구축합니다.
우리의 모든 모델은 동일한 데이터셋에서 SVM 모델을 사용한 이전 연구와 유사한 성능을 달성했습니다 [79].

**Drebin**
129,013개의 Android 애플리케이션을 포함한 데이터셋으로, 그 중 123,453개는 정상이고 5,560개는 악성입니다.
이 데이터셋에는 매니페스트 파일(예: 요청된 권한 및 인텐트)과 분해된 코드(예: 제한된 API 호출 및 네트워크 주소)에서 캡처된 특징을 포함하여 8개의 세트로 분류된 총 545,333개의 이진 특징이 있습니다.
DNN의 가중치가 제공되지 않기 때문에, 우리는 데이터셋에서 임의로 선택한 66%의 Android 애플리케이션을 사용하여 이 세 가지 DNN을 훈련하고 나머지를 테스트 세트로 사용합니다.

### 6.2 Domain-specific constraints
앞서 논의한 바와 같이, 실무에서 유용하려면 생성된 테스트가 유효하고 현실적인지 도메인별 제약 조건을 적용하여 확인해야 합니다.
마찬가지로, 생성된 PDF는 PDF 뷰어가 테스트 파일을 열 수 있도록 PDF 사양을 따라야 합니다.
아래에서는 이 논문에서 사용하는 두 가지 주요 도메인별 제약 조건(즉, 이미지 제약 조건 및 파일 제약 조건)에 대해 설명합니다.

**Image constraints (MNIST, ImageNet, and Driving)**
DeepXplore는 이미지의 다양한 환경 조건을 시뮬레이션하기 위해 세 가지 다른 유형의 제약 조건을 사용했습니다:
(1) 다양한 조명의 강도를 시뮬레이션하기 위한 조명 효과, (2) 카메라의 일부를 잠재적으로 차단할 수 있는 공격자를 시뮬레이션하기 위한 단일 작은 사각형에 의한 폐색, (3) 카메라 렌즈에 먼지가 있는 효과를 시뮬레이션하기 위한 여러 개의 작은 검은 사각형에 의한 폐색.

첫 번째 제약 조건은 이미지의 내용을 변경하지 않고 DeepXplore가 이미지를 어둡게 또는 밝게만 만들 수 있도록 이미지 수정을 제한합니다.
구체적으로, 수정은 모든 픽셀 값을 동일한 양만큼 증가시키거나 감소시킬 수 있습니다(예: 알고리즘 1의 14번째 줄에서 1 * *stepsize*)—증가 또는 감소 결정은 그래디언트 상승의 각 반복에서 계산된 그래디언트를 나타내는 G의 평균값 mean(G)에 따라 달라집니다.
mean(G)는 다차원 배열 G의 모든 항목의 평균을 단순히 나타냅니다.
그림 8의 첫 번째와 두 번째 행은 이러한 제약 조건으로 DeepXplore가 생성한 차이 유발 입력의 몇 가지 예를 보여줍니다.

![Figure 8](/posts/paper/DeepXplore/figure8.png)

두 번째 제약 조건은 카메라 렌즈가 실수로 또는 의도적으로 작은 사각형 \(R\) (m × n 픽셀)에 의해 가려지는 효과를 시뮬레이션합니다.
구체적으로, 우리는 원본 이미지 \(I\)에 대해 \( G_{i:i+m,j:j+n} \)만 적용하며, 여기서 \(I_{i:i+m,j:j+n}\)는 \(R\)의 위치입니다.
DeepXplore는 사각형 \( R \)을 이미지 내의 임의의 위치에 배치하기 위해 \( i \)와 \( j \)의 값을 자유롭게 선택할 수 있습니다.
그림 8의 세 번째와 네 번째 행은 이러한 폐색 제약 조건을 적용하여 DeepXplore가 생성한 예제를 보여줍니다.

세 번째 제약 조건은 수정 사항을 제한하여 DeepXplore가 그래디언트 상승의 각 반복 동안 \( (i, j) \)의 좌상단 코너를 가지는 \( G \)에서 \( m \times m \) 크기의 작은 패치 \( G_{i:i+m,j:j+m} \)만 선택하도록 합니다.
이 패치의 평균값 \( \text{mean}(G_{i:i+m,j:j+m}) \)가 0보다 크면, \( G_{i:i+m,j:j+m} = 0 \)으로 설정합니다.
즉, 우리는 픽셀 값이 감소하는 것만 허용합니다.
위에서 설명한 두 번째 제약 조건과 달리, 여기서 DeepXplore는 카메라 렌즈의 먼지를 시뮬레이션하기 위해 검은 사각형을 배치할 여러 위치(즉, 여러 \( (i, j) \) 쌍)를 선택합니다.
그림 8의 다섯 번째와 여섯 번째 행은 이러한 제약 조건으로 생성된 예제를 보여줍니다.

