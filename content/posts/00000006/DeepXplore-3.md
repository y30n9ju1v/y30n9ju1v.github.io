+++
title = 'DeepXplore 3'
date = 2024-08-07T12:10:55+09:00
draft = false 
+++

이 글은 DeepXplore: Automated Whitebox Testing of Deep Learning Systems (https://arxiv.org/abs/1705.06640)을 번역 및 요약한 글입니다.
[DeepXplore 2]({{< ref "DeepXplore-2" >}}) 에서 이어집니다.

## 7. Results
**Summary** DeepXplore는 테스트된 모든 DNN에서 수천 개의 오류 동작을 발견했습니다.
표 2는 각 테스트된 DNN에 대해 DeepXplore가 발견한 오류 동작의 수를 요약한 것입니다.
이는 해당 테스트 세트에서 무작위로 선택된 2,000개의 시드 입력을 사용하여 수행되었습니다.
이러한 실험의 하이퍼파라미터 값은 표 2에 나와 있으며, 이는 차이 유발 입력을 찾는 비율과 이러한 입력이 달성한 뉴런 커버리지를 최대화하기 위해 경험적으로 선택되었습니다.

![Table 2](/posts/paper/DeepXplore/table2.png)

실험 결과를 보여주는 그림 8에서는 § 6.2에 설명된 세 가지 도메인 특화 제약 조건(조명 효과, 단일 사각형에 의한 가림, 여러 사각형에 의한 가림)을 적용했습니다.
시각 관련 작업을 포함한 다른 모든 실험에서는 조명 효과만 도메인 특화 제약 조건으로 사용했습니다.
별도로 명시되지 않는 한, 모든 실험에서 표 2에 나열된 하이퍼파라미터 값을 사용했습니다.

![Figure 8](/posts/paper/DeepXplore/figure8.png)

그림 8은 MNIST, ImageNet, 및 Driving 데이터셋에 대해 DeepXplore가 생성한 (다양한 도메인 특화 제약 조건을 사용한) 차이 유발 입력과 해당 오류 동작을 보여줍니다.
표 3 (Drebin) 및 표 4 (Contagio/VirusTotal)는 DeepXplore가 생성한 두 개의 차이 유발 입력을 보여주며, 이는 테스트된 DNN에서 오류 동작을 유발했습니다.

![Table 3](/posts/paper/DeepXplore/table3.png)
![Table 4](/posts/paper/DeepXplore/table4.png)

### 7.1 Benefits of neuron coverage
이 절에서는 뉴런 커버리지라는 새로운 메트릭이 DNN 테스트의 포괄성을 측정하는 데 얼마나 효과적인지를 평가합니다.
최근 연구에 따르면, DNN의 각 뉴런은 다른 뉴런들과 협력하여 특징을 추출하는 대신 독립적으로 입력의 특정 특징을 추출하는 경향이 있습니다 [58, 87].
본질적으로, 각 뉴런은 다른 뉴런들과 다른 규칙 세트를 학습하는 경향이 있습니다.
이 발견은 뉴런 커버리지가 DNN 테스트의 포괄성을 위한 좋은 메트릭인 이유를 직관적으로 설명합니다.
이러한 관찰을 실증적으로 확인하기 위해, 우리는 아래에 설명된 두 가지 다른 실험을 수행했습니다.

첫째, 우리는 뉴런 커버리지가 DNN 테스트 입력의 포괄성을 측정하는 데 있어 코드 커버리지보다 훨씬 더 나은 메트릭임을 보여줍니다.
더 구체적으로, 소수의 테스트 입력만으로도 모든 DNN에서 100% 코드 커버리지를 달성할 수 있지만, 실제 뉴런 커버리지는 34% 미만임을 발견했습니다.
둘째, 우리는 서로 다른 클래스의 테스트 입력에 대한 뉴런 활성화를 평가했습니다.
결과는 서로 다른 클래스의 입력이 동일한 클래스의 입력보다 더 많은 고유 뉴런을 활성화하는 경향이 있음을 보여줍니다.
두 가지 발견 모두 뉴런 커버리지가 입력에 의해 실행되는 DNN 규칙의 수와 유형을 잘 추정할 수 있음을 확인시켜줍니다.

**Neuron coverage vs code coverage**
우리는 § 6.1에서 설명한 대로 무작위로 선택된 10개의 테스트 샘플을 사용하여 테스트 DNN을 평가함으로써 동일한 수의 입력으로 달성된 코드 커버리지와 뉴런 커버리지를 비교합니다.
DNN의 코드 커버리지는 학습 및 테스트 과정에서 사용된 파이썬 코드의 라인 커버리지 측면에서 측정합니다.
뉴런 커버리지에서 임계값 t를 0.75로 설정하여, 뉴런이 적어도 하나의 입력에 대해 출력이 0.75를 초과하는 경우에만 해당 뉴런이 커버된 것으로 간주합니다.

중간 계층의 출력이 최종 계층의 출력과 다른 범위의 값을 생성하는 DNN의 경우, 뉴런 출력을 [0, 1] 범위로 스케일링합니다.
이는 주어진 계층의 모든 뉴런 출력을 나타내는 벡터 out에 대해 (out − min(out)) / (max(out) − min(out))를 계산하여 수행합니다.

결과는 표 6에 나와 있으며, 뉴런 커버리지가 DNN 테스트의 포괄성을 측정하는 데 코드 커버리지보다 훨씬 더 나은 메트릭임을 명확히 보여줍니다.
무작위로 선택한 10개의 입력만으로도 모든 DNN에서 100% 코드 커버리지를 달성할 수 있는 반면, 뉴런 커버리지는 어떤 DNN에서도 34%를 넘지 못했습니다.
또한, 뉴런 커버리지는 테스트된 DNN과 테스트 입력에 따라 크게 달라집니다.
예를 들어, 전체 MNIST 테스트 세트(즉, 10,000개의 테스트 샘플)에 대한 뉴런 커버리지는 C1, C2, C3에 대해 각각 57.7%, 76.4%, 83.6%에 불과합니다.
반면에, 전체 Contagio/Virustotal 테스트 세트에 대한 뉴런 커버리지는 100%에 도달합니다.

![Table 6](/posts/paper/DeepXplore/table6.png)

**Effect of neuron coverage on the difference-inducing inputs found by DeepXplore**
공동 최적화 과정에서 뉴런 커버리지를 극대화하는 주요 목표는 다양한 차이 유발 입력을 생성하는 것입니다(§ 3에서 논의됨).
이 실험에서는 뉴런 커버리지가 이 목표를 달성하는 데 얼마나 효과적인지를 평가합니다.

우리는 MNIST 테스트 데이터셋에서 무작위로 2,000개의 시드 입력을 선택하고, DeepXplore를 사용하여 뉴런 커버리지를 포함하거나 제외하여 차이 유발 입력을 생성합니다.
이를 위해 식 2에서 λ2를 각각 1과 0으로 설정합니다.
생성된 차이 유발 입력의 다양성은 동일한 시드에서 생성된 모든 차이 유발 입력과 원래 시드 간의 평균 L1 거리로 측정합니다.
L1 거리는 생성된 이미지와 원본 이미지 간의 각 픽셀 값의 절대 차이의 합을 계산합니다.
표 5는 이러한 세 가지 실험의 결과를 보여줍니다.
결과는 뉴런 커버리지가 생성된 입력의 다양성을 증가시키는 데 도움이 됨을 명확히 보여줍니다.

![Table 5](/posts/paper/DeepXplore/table5.png)

λ2 = 0 대신 λ2 = 1로 설정하여 달성한 뉴런 커버리지 증가의 절대 값이 작아 보일 수 있지만(예: 1-2 퍼센트 포인트), 표 5에서 보듯이 생성된 차이 유발 이미지의 다양성을 증가시키는 데는 큰 영향을 미칩니다.
이러한 결과는 코드 커버리지와 마찬가지로 뉴런 커버리지를 증가시키는 것이 높은 값에서 점점 더 어려워지지만, 뉴런 커버리지의 작은 증가도 테스트 다양성을 크게 향상시킬 수 있음을 보여줍니다.
또한, λ2 = 1로 설정하면 DeepXplore가 단순히 동일한 근본 원인을 가진 차이를 늘리는 대신 다양한 차이를 찾는 데 집중하게 되므로, λ2 = 1로 설정한 경우 생성된 차이 유발 입력의 수는 λ2 = 0일 때보다 적습니다.
일반적으로, 단순히 차이 유발 입력의 수만으로는 시각 관련 작업에 대한 생성된 테스트의 품질을 측정하는 좋은 메트릭이 되지 않습니다.
왜냐하면 기존의 차이 유발 이미지에 작은 변화를 주어 동일한 근본 원인을 가진 많은 차이 유발 이미지를 만들 수 있기 때문입니다.

**Activation of neurons for different classes of inputs**
이 실험에서는 동일한 클래스와 다른 클래스의 MNIST 입력 쌍에 대해 LeNet-5 DNN에서 공통으로 활성화된 뉴런의 수를 측정합니다.
그런 다음, 이러한 입력 쌍에 대해 공통으로 활성화된 뉴런의 수를 계산합니다.
표 7은 결과를 보여주며, 이는 동일한 클래스에서 온 입력이 다른 클래스에서 온 입력보다 더 많은 활성화된 뉴런을 공유한다는 우리의 가설을 확인시켜줍니다.
서로 다른 클래스의 입력은 서로 다른 DNN 규칙의 매칭을 통해 탐지되는 경향이 있기 때문에, 우리의 결과는 뉴런 커버리지가 DNN 테스트 동안 활성화된 다양한 규칙의 수를 효과적으로 추정할 수 있음을 또한 확인해줍니다.

![Table 7](/posts/paper/DeepXplore/table7.png)

### 7.2 Performance
**Neuron coverage**
이 실험에서는 세 가지 다른 접근 방식으로 생성된 동일한 수의 테스트에 의해 달성된 뉴런 커버리지를 비교합니다:
(1) DeepXplore, (2) 적대적 테스트 [26], (3) 원래 테스트 세트에서 무작위 선택. 결과는 표 8과 그림 9에 나와 있습니다.

![Table 8](/posts/paper/DeepXplore/table8.png)
![Figure 9](/posts/paper/DeepXplore/figure9.png)

결과에서 두 가지 주요 관찰을 할 수 있습니다.
첫째, 그림 9에서 보여주듯이, DeepXplore는 평균적으로 무작위 테스트와 적대적 테스트보다 각각 34.4% 및 33.2% 더 많은 뉴런을 커버합니다.
둘째, 뉴런이 활성화되었을 때를 결정하는 뉴런 커버리지 임계값 t(§ 4에서 정의됨)은 달성된 뉴런 커버리지에 큰 영향을 미칩니다.

**Execution time and number of seed inputs**
이 실험에서는 테스트된 모든 DNN에 대해 100% 뉴런 커버리지를 달성하면서 차이 유발 입력을 생성하는 DeepXplore의 실행 시간을 측정합니다.
MNIST, ImageNet, 그리고 Driving 데이터셋의 DNN에서 일부 완전 연결 계층의 뉴런들은 활성화하기 매우 어려운 점을 고려하여, 완전 연결 계층을 제외한 계층들에 대한 뉴런 커버리지만을 고려합니다.
표 8은 결과를 보여주며, 이는 DeepXplore가 차이 유발 입력을 찾고 뉴런 커버리지를 증가시키는 데 있어 매우 효율적임을 나타냅니다.

**Different choices of hyperparameters**
우리는 DeepXplore의 다양한 하이퍼파라미터(s, λ1, λ2, t; § 4.2에 설명됨)가 DeepXplore의 성능에 어떻게 영향을 미치는지 추가로 평가합니다.
뉴런 활성화 임계값 t의 변화를 보여주는 결과는 앞서 설명한 그림 9에 나와 있습니다.
표 9, 10, 11은 각각 s, λ1, λ2의 변화에 따른 DeepXplore 실행 시간의 변화를 보여줍니다.
우리의 결과는 DNN과 데이터셋에 따라 s와 λ1의 최적 값이 다르며, λ2 = 0.5가 모든 데이터셋에 대해 최적의 값을 가지는 경향이 있음을 보여줍니다.

![Table 9](/posts/paper/DeepXplore/table9.png)
![Table 10](/posts/paper/DeepXplore/table10.png)
![Table 11](/posts/paper/DeepXplore/table11.png)

**Testing very similar models with DeepXplore**
DeepXplore의 기울기 기반 테스트 생성 프로세스는 실제로 매우 잘 작동하지만, 특히 매우 유사한 결정 경계를 가진 DNN의 경우 일부 사례에서는 합리적인 시간 내에 차이 유발 입력을 찾지 못할 수 있습니다.
DeepXplore가 실제로 실패하게 만드는 두 DNN의 유사도가 얼마나 되어야 하는지를 추정하기 위해, 우리는 두 DNN 간의 세 가지 유형의 차이를 제어하고 각 경우에 첫 번째 차이 유발 입력을 생성하는 데 필요한 반복 횟수의 변화를 측정합니다.

우리는 MNIST 훈련 세트(60,000개의 샘플)와 10번의 에포크로 학습된 LeNet-1을 대조군으로 사용합니다.
LeNet-1의 변형을 만들기 위해 (1) 훈련 샘플 수, (2) 각 컨볼루션 계층당 필터 수, (3) 훈련 에포크 수를 각각 변경합니다.
표 12는 이러한 LeNet-1 변형과 원본 버전 간에 첫 번째 차이 유발 입력을 찾는 데 DeepXplore가 필요한 평균 반복 횟수(100개의 시드 입력에 대한 평균)를 요약한 것입니다.

![Table 12](/posts/paper/DeepXplore/table12.png)

### 7.3 Improving DNNs with DeepXplore
**Augmenting training data to improve accuracy**
우리는 DeepXplore가 생성한 오류 유발 입력을 사용하여 DNN의 원래 학습 데이터를 증강하고, 이를 통해 DNN을 재학습시켜 오류 동작을 수정하고 정확도를 향상시킵니다.
이러한 전략은 적대적 입력에 대한 DNN의 동작을 수정하기 위해서도 채택되었지만 [26], 중요한 차이점은 적대적 테스트는 수작업으로 레이블을 지정해야 하는 반면, DeepXplore는 다수결 투표 [23]를 채택하여 생성된 테스트 입력에 대해 자동으로 레이블을 생성할 수 있다는 점입니다.
이 접근 방식을 평가하기 위해, 우리는 LeNet-1, LeNet-4, 그리고 LeNet-5를 표 1에 나타낸 대로 60,000개의 원본 샘플로 학습시켰습니다.
추가로 100개의 새로운 오류 유발 샘플을 추가하여 학습 데이터를 증강하고, DNN을 5번의 에포크 동안 재학습시켰습니다.
세 가지 접근 방식, 즉 랜덤 선택("random"), 적대적 테스트("adversarial"), 그리고 DeepXplore을 비교한 실험 결과는 그림 10에 나타나 있습니다.
결과는 DeepXplore이 적대적 및 랜덤 증강보다 평균 정확도를 1-3% 더 향상시켰음을 보여줍니다.

**Detecting training data pollution attack**
DeepXplore의 또 다른 응용으로, 우리는 이를 사용하여 훈련 데이터 오염 공격을 감지하는 방법을 시연합니다.
하나는 MNIST 데이터셋의 60,000개의 손글씨 숫자로 학습된 모델이고, 다른 하나는 동일한 데이터셋의 인위적으로 오염된 버전으로 학습된 모델입니다.
오염된 데이터셋에서는 원래 숫자 9로 레이블된 이미지의 30%가 1로 잘못 레이블되었습니다.
우리는 DeepXplore를 사용하여 오류를 유발하는 입력을 생성했으며, 이는 각각 오염되지 않은 LeNet-5 DNN과 오염된 LeNet-5 DNN에서 숫자 9와 1로 분류됩니다.
그런 다음 구조적 유사성 [80]을 기준으로 DeepXplore가 생성한 입력과 가장 가까운 훈련 세트의 샘플을 찾아 이를 오염된 데이터로 식별했습니다.
이 과정을 통해 우리는 95.6%의 오염된 샘플을 정확히 식별할 수 있었습니다.

## 8. Discussion
**Causes of differences between DNNs**
같은 입력에 대해 두 DNN의 예측 차이의 근본 원인은 결정 논리/경계의 차이입니다.
§ 2.1에서 설명한 바와 같이, DNN의 결정 논리는 훈련 데이터, DNN 아키텍처, 하이퍼파라미터 등 여러 요인에 의해 결정됩니다.
따라서 이러한 요인의 선택에 차이가 있으면 결과적인 DNN의 결정 논리에 미묘한 변화가 발생합니다.
우리가 표 12에서 실증적으로 보여주었듯이, 두 DNN의 결정 경계가 더 유사할수록 차이를 유발하는 입력을 찾기가 더 어렵습니다.
그러나 우리가 테스트한 모든 실세계 DNN은 상당한 차이점을 가지고 있어 DeepXplore는 테스트된 모든 DNN에서 잘못된 동작을 효율적으로 찾을 수 있습니다.

**Overhead of training vs. testing DNNs**
대규모 실세계 DNN의 예측/그래디언트 계산과 훈련 간에는 상당한 성능 비대칭이 존재합니다.
예를 들어, ImageNet 데이터셋 [61] 대회에서 120만 개의 이미지로 최신 DNN인 VGG-16 [66](이 논문에서 테스트된 DNN 중 하나)을 훈련시키는 데에는 단일 GTX 1080 Ti GPU에서 최대 7일이 걸릴 수 있습니다.
반면에, 동일한 GPU에서 예측 및 그래디언트 계산은 이미지당 총 약 120밀리초가 소요됩니다.
대규모 DNN의 훈련과 예측 간의 이러한 엄청난 성능 차이는 DeepXplore가 대규모 사전 훈련된 DNN을 테스트하는 데 특히 적합하게 만듭니다.

**Limitations**
DeepXplore는 소프트웨어 분석에서 차분 테스트 기법을 채택하여 차분 테스트의 한계를 상속받습니다.
이러한 한계를 간단히 요약하면 다음과 같습니다.

첫째, 차분 테스트는 동일한 기능을 가진 최소 두 개의 서로 다른 DNN을 필요로 합니다.
또한, 두 DNN이 약간만 다를 경우(즉, 몇 개의 뉴런에 의해), DNN 간에 상당한 차이가 있는 경우보다 DeepXplore가 차이를 유발하는 입력을 찾는 데 더 오래 걸립니다(표 12 참조).
그러나 우리의 평가에 따르면, 대부분의 경우 주어진 문제에 대해 여러 다른 DNN을 쉽게 구할 수 있으며, 개발자들은 종종 맞춤화 및 정확도 향상을 위해 자신의 DNN을 정의하고 훈련합니다.

둘째, 차분 테스트는 적어도 하나의 DNN이 다른 DNN과 다른 결과를 생성할 때만 잘못된 동작을 감지할 수 있습니다.
테스트된 모든 DNN이 동일한 실수를 하면, DeepXplore는 해당 테스트 케이스를 생성할 수 없습니다.
그러나 대부분의 DNN이 독립적으로 구성되고 훈련되기 때문에, 모든 DNN이 동일한 실수를 할 가능성은 낮아 실무에서는 이것이 큰 문제가 되지 않는 것으로 나타났습니다.

## 9. Related Work
**Adversarial deeplearning**
최근 머신 러닝 [26, 49, 72]과 보안 [12, 21, 22, 55, 63, 74, 82] 커뮤니티 모두에서 머신 러닝의 보안 및 프라이버시 측면이 큰 주목을 받고 있습니다.
많은 연구는 DNN이 원래는 정확히 분류한 입력 이미지에 미세한 변화를 적용하면, 인간의 눈으로는 원본 이미지와 구별할 수 없지만 수정된 이미지로 인해 DNN이 속을 수 있음을 보여주었습니다.
그러나 이들은 두 가지 주요 한계가 있습니다: (1) 뉴런 커버리지가 낮아(그림 9에서 보듯이 무작위로 선택된 테스트 입력과 유사) DeepXplore와 달리 다양한 유형의 오류 동작을 노출할 수 없습니다; (2) 적대적 이미지 생성 과정은 본질적으로 미세하고 감지 불가능한 변형만을 사용하도록 제한됩니다.
눈에 띄는 변화를 사용하면 수동 검사가 필요하기 때문입니다.
DeepXplore는 차등 테스트를 사용하여 이 문제를 해결하며, 다양한 현실적인 눈에 띄는 차이(예: 다른 조명, 가림 등)를 만들기 위해 입력을 변형할 수 있고, 이러한 상황에서 DNN의 오류 동작을 자동으로 감지할 수 있습니다.

**Testing and verification of DNNs**
전통적인 머신 러닝 시스템 평가 방법은 주로 수동으로 라벨링된 데이터셋에서 무작위로 추출한 테스트 입력에 대한 정확도를 측정합니다 [81].
자율 주행 차량과 같은 일부 머신 러닝 시스템은 임시의 비유도 시뮬레이션을 활용합니다 [2, 4].
그러나 모델의 내부에 대한 지식 없이 이러한 블랙박스 테스트 패러다임은 오류 동작을 유발하는 다양한 코너 케이스를 찾지 못합니다 [25].
이러한 관찰은 여러 연구자들이 DNN의 견고성과 신뢰성을 향상시키기 위한 연구를 시도하게 만들었습니다 [9, 13, 17, 30, 32, 46, 51, 53, 62, 84, 89, 90].
그러나 이러한 프로젝트는 모두 적대적 입력에만 집중하고 수동으로 제공된 실제 레이블에 의존합니다.
반면, 우리의 기술은 수동 라벨링 없이 완전히 자동화된 방식으로 다양한 결함에 대해 딥러닝 시스템의 견고성과 신뢰성을 체계적으로 테스트할 수 있습니다.
또 다른 최근 연구는 다양한 안전 속성에 대해 DNN을 형식적으로 검증하는 가능성을 탐구했습니다 [32, 37, 57].
이러한 기법들은 실제 세계의 DNN에 대해 흥미로운 안전 속성 위반을 찾는 데 있어서 잘 확장되지 않습니다.
반면에 DeepXplore는 크고 최신의 DNN에서 흥미로운 오류 동작을 찾을 수 있지만, 특정 DNN이 주어진 안전 속성을 만족하는지에 대한 보장을 제공할 수는 없습니다.

**Other applications of DNN gradients**
기울기는 과거에 객체 분할 [44, 66], 두 이미지 간의 예술적 스타일 전환 [24, 43, 59] 등과 같은 작업을 위해 DNN의 다양한 중간 계층의 활성화를 시각화하는 데 사용되었습니다.
이에 반해, 본 논문에서는 기울기 상승법을 적용하여 테스트된 DNN들 간의 뉴런 커버리지와 차별적 행동의 수를 모두 극대화하는 공동 최적화 문제를 해결합니다.

## 10. Conclusion
우리는 DL 시스템을 체계적으로 테스트하고 수작업 라벨 없이 잘못된 동작을 자동으로 식별하는 최초의 백박스 시스템인 DeepXplore를 설계하고 구현했습니다.
우리는 입력 집합에 의해 DNN의 몇 가지 규칙이 실행되는지를 측정하는 새로운 지표인 뉴런 커버리지를 도입했습니다.
DeepXplore는 뉴런 커버리지와 잠재적인 잘못된 동작의 수를 모두 극대화하는 공동 최적화 문제를 해결하기 위해 그래디언트 상승을 수행합니다.
DeepXplore는 다섯 개의 실세계 데이터셋에서 훈련된 15개의 최신 DNN에서 수천 개의 잘못된 동작을 발견할 수 있었습니다.

