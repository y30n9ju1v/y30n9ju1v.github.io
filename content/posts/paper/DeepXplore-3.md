+++
title = 'DeepXplore 3'
date = 2024-07-14T12:10:55+09:00
draft = true
+++

이 글은 DeepXplore: Automated Whitebox Testing of Deep Learning Systems (https://arxiv.org/abs/1705.06640)을 번역한 글입니다.

## 6. Experimental Setup
### 6.1 Test datasets and DNNs

우리는 서로 다른 유형의 데이터를 가진 다섯 개의 인기 있는 공개 데이터셋—MNIST, ImageNet, Driving, Contagio/VirusTotal, Drebin—을 채택하고, 각 데이터셋에 대해 세 개의 DNN에서 DeepXplore를 평가합니다(즉, 총 15개의 DNN).
다섯 개의 데이터셋과 해당 DNN에 대한 요약은 표 1에 제공됩니다.
평가된 모든 DNN은 이전 연구자들이 보고한 공개 가중치를 사용하거나, 해당 데이터셋에 대해 최신 모델과 유사한 성능을 달성하기 위해 우리가 공용 실제 아키텍처를 사용하여 훈련한 것입니다.
각 데이터셋에 대해, 우리는 표 1에 설명된 대로 서로 다른 아키텍처를 가진 세 개의 DNN을 테스트하기 위해 DeepXplore를 사용했습니다.

![Table 1](/posts/DeepXplore/table1.png)

**MNIST**
28x28 픽셀 이미지와 0부터 9까지의 클래스 라벨을 포함한 대규모 손글씨 숫자 데이터셋입니다.
이 데이터셋은 60,000개의 훈련 샘플과 10,000개의 테스트 샘플을 포함합니다.
우리는 Lecun 등 [40]을 따라 LeNet 계열 [40]을 기반으로 한 세 개의 다른 신경망, 즉 LeNet-1, LeNet-4, LeNet-5를 구성합니다.

**ImageNet**
10,000,000개 이상의 수작업으로 주석이 달린 이미지를 포함한 대규모 이미지 데이터셋으로, 크라우드소싱으로 수집되고 수작업으로 라벨링되었습니다.
우리는 세 개의 잘 알려진 사전 훈련된 DNN을 테스트합니다: VGG-16 [66], VGG-19 [66], ResNet50 [31].
이 세 DNN 모두 ILSVRC [61] 대회에서 경쟁력 있는 성능을 달성했습니다.

**Driving**
Udacity 자율 주행 자동차 챌린지 데이터셋으로, 주행 중인 자동차의 앞 유리에 장착된 카메라로 촬영한 이미지와 각 이미지에 대해 인간 운전자가 적용한 스티어링 휠 각도를 포함합니다.
이 데이터셋은 101,396개의 훈련 샘플과 5,614개의 테스트 샘플을 포함합니다.
우리는 Nvidia [10]의 DAVE-2 자율 주행 자동차 아키텍처를 기반으로 약간 다른 구성의 세 개의 DNN [8, 18, 78]을 사용했습니다.
이들은 각각 DAVE-orig, DAVE-norminit, DAVE-dropout이라고 불립니다.
구체적으로, DAVE-orig [8]은 Nvidia 논문 [10]의 원래 아키텍처를 완전히 복제합니다.
DAVE-norminit [78]은 첫 번째 배치 정규화 층을 제거하고 무작위로 초기화된 네트워크 가중치를 정규화합니다.
DAVE-dropout [18]은 컨볼루션 층과 완전 연결 층의 수를 줄여 DAVE-orig를 단순화합니다.
DAVE-dropout은 또한 마지막 세 개의 완전 연결 층 사이에 두 개의 드롭아웃 층 [70]을 추가합니다.
우리는 위에 언급된 Udacity 자율 주행 자동차 챌린지 데이터셋으로 세 가지 구현을 모두 훈련했습니다.

**Contagio/VirusTotal**
다양한 정상 및 악성 PDF 문서를 포함하는 데이터셋입니다.
우리는 Contagio 데이터베이스에서 가져온 5,000개의 정상 PDF 문서와 12,205개의 악성 PDF 문서를 훈련 세트로 사용하고, VirusTotal [77]에서 수집한 5,000개의 악성 PDF와 Google에서 크롤링한 5,000개의 정상 PDF를 테스트 세트로 사용합니다.
우리가 알기로는 공개적으로 사용 가능한 DNN 기반 PDF 악성 코드 탐지 시스템이 없습니다.
따라서, 우리는 PDF 악성 코드 탐지를 위한 온라인 서비스인 PDFrate [54, 68]에서 135개의 정적 특징을 사용하여 세 가지 다른 DNN을 정의하고 훈련합니다.
구체적으로, 우리는 하나의 입력층, 하나의 소프트맥스 출력층, 그리고 N개의 200개 뉴런이 있는 완전 연결 은닉층으로 구성된 신경망을 구축합니다.
여기서 N은 테스트된 세 가지 DNN 각각에 대해 2에서 4까지 범위입니다.
우리의 모든 모델은 동일한 데이터셋에서 SVM 모델을 사용한 이전 연구와 유사한 성능을 달성했습니다 [79].

**Drebin**
129,013개의 Android 애플리케이션을 포함한 데이터셋으로, 그 중 123,453개는 정상이고 5,560개는 악성입니다.
이 데이터셋에는 매니페스트 파일(예: 요청된 권한 및 인텐트)과 분해된 코드(예: 제한된 API 호출 및 네트워크 주소)에서 캡처된 특징을 포함하여 8개의 세트로 분류된 총 545,333개의 이진 특징이 있습니다.
우리는 Grosse 등 [29]이 구성한 36개의 DNN 중 3개의 아키텍처를 채택합니다.
DNN의 가중치가 제공되지 않기 때문에, 우리는 데이터셋에서 임의로 선택한 66%의 Android 애플리케이션을 사용하여 이 세 가지 DNN을 훈련하고 나머지를 테스트 세트로 사용합니다.

### 6.2 Domain-specific constraints
앞서 논의한 바와 같이, 실무에서 유용하려면 생성된 테스트가 유효하고 현실적인지 도메인별 제약 조건을 적용하여 확인해야 합니다.
예를 들어, 생성된 이미지는 카메라로 물리적으로 생성할 수 있어야 합니다.
마찬가지로, 생성된 PDF는 PDF 뷰어가 테스트 파일을 열 수 있도록 PDF 사양을 따라야 합니다.
아래에서는 이 논문에서 사용하는 두 가지 주요 도메인별 제약 조건(즉, 이미지 제약 조건 및 파일 제약 조건)에 대해 설명합니다.

**Image constraints (MNIST, ImageNet, and Driving)**
DeepXplore는 이미지의 다양한 환경 조건을 시뮬레이션하기 위해 세 가지 다른 유형의 제약 조건을 사용했습니다: (1) 다양한 조명의 강도를 시뮬레이션하기 위한 조명 효과, (2) 카메라의 일부를 잠재적으로 차단할 수 있는 공격자를 시뮬레이션하기 위한 단일 작은 사각형에 의한 폐색, (3) 카메라 렌즈에 먼지가 있는 효과를 시뮬레이션하기 위한 여러 개의 작은 검은 사각형에 의한 폐색.

첫 번째 제약 조건은 이미지의 내용을 변경하지 않고 DeepXplore가 이미지를 어둡게 또는 밝게만 만들 수 있도록 이미지 수정을 제한합니다.
구체적으로, 수정은 모든 픽셀 값을 동일한 양만큼 증가시키거나 감소시킬 수 있습니다(예: 알고리즘 1의 14번째 줄에서 1 * *stepsize*)—증가 또는 감소 결정은 그래디언트 상승의 각 반복에서 계산된 그래디언트를 나타내는 G의 평균값 mean(G)에 따라 달라집니다.
mean(G)는 다차원 배열 G의 모든 항목의 평균을 단순히 나타냅니다.
그림 8의 첫 번째와 두 번째 행은 이러한 제약 조건으로 DeepXplore가 생성한 차이 유발 입력의 몇 가지 예를 보여줍니다.

두 번째 제약 조건은 카메라 렌즈가 실수로 또는 의도적으로 작은 사각형 \(R\) (m × n 픽셀)에 의해 가려지는 효과를 시뮬레이션합니다.
구체적으로, 우리는 원본 이미지 \(I\)에 대해 \( G_{i:i+m,j:j+n} \)만 적용하며, 여기서 \(I_{i:i+m,j:j+n}\)는 \(R\)의 위치입니다.
DeepXplore는 사각형 \( R \)을 이미지 내의 임의의 위치에 배치하기 위해 \( i \)와 \( j \)의 값을 자유롭게 선택할 수 있습니다.
그림 8의 세 번째와 네 번째 행은 이러한 폐색 제약 조건을 적용하여 DeepXplore가 생성한 예제를 보여줍니다.

세 번째 제약 조건은 수정 사항을 제한하여 DeepXplore가 그래디언트 상승의 각 반복 동안 \( (i, j) \)의 좌상단 코너를 가지는 \( G \)에서 \( m \times m \) 크기의 작은 패치 \( G_{i:i+m,j:j+m} \)만 선택하도록 합니다.
이 패치의 평균값 \( \text{mean}(G_{i:i+m,j:j+m}) \)가 0보다 크면, \( G_{i:i+m,j:j+m} = 0 \)으로 설정합니다.
즉, 우리는 픽셀 값이 감소하는 것만 허용합니다.
위에서 설명한 두 번째 제약 조건과 달리, 여기서 DeepXplore는 카메라 렌즈의 먼지를 시뮬레이션하기 위해 검은 사각형을 배치할 여러 위치(즉, 여러 \( (i, j) \) 쌍)를 선택합니다.
그림 8의 다섯 번째와 여섯 번째 행은 이러한 제약 조건으로 생성된 예제를 보여줍니다.

**Other constraints (Drebin and Contagio/VirusTotal)**
Drebin 데이터셋의 경우, DeepXplore는 Android 매니페스트 파일과 관련된 특징만 수정하도록 제한을 적용하여 애플리케이션 코드가 영향을 받지 않도록 합니다.
또한, DeepXplore는 매니페스트 파일에서 특징을 삭제(1에서 0으로 변경)하지 않고 특징을 추가(0에서 1로 변경)하는 것만 허용하여, 권한 부족으로 인해 애플리케이션 기능이 변경되지 않도록 보장합니다.
따라서, 그래디언트를 계산한 후, DeepXplore는 해당 그래디언트가 0보다 큰 매니페스트 특징만 수정합니다.

Contagio/VirusTotal 데이터셋의 경우, DeepXplore는 Šrndic 등 [79]에 의해 설명된 각 특징에 대한 제한을 따릅니다.

## 7. Results

## 8. Discussion
**Causes of differences between DNNs**
같은 입력에 대해 두 DNN의 예측 차이의 근본 원인은 결정 논리/경계의 차이입니다.
§ 2.1에서 설명한 바와 같이, DNN의 결정 논리는 훈련 데이터, DNN 아키텍처, 하이퍼파라미터 등 여러 요인에 의해 결정됩니다.
따라서 이러한 요인의 선택에 차이가 있으면 결과적인 DNN의 결정 논리에 미묘한 변화가 발생합니다.
우리가 표 12에서 실증적으로 보여주었듯이, 두 DNN의 결정 경계가 더 유사할수록 차이를 유발하는 입력을 찾기가 더 어렵습니다.
그러나 우리가 테스트한 모든 실세계 DNN은 상당한 차이점을 가지고 있어 DeepXplore는 테스트된 모든 DNN에서 잘못된 동작을 효율적으로 찾을 수 있습니다.

**Overhead of training vs. testing DNNs**
대규모 실세계 DNN의 예측/그래디언트 계산과 훈련 간에는 상당한 성능 비대칭이 존재합니다.
예를 들어, ImageNet 데이터셋 [61] 대회에서 120만 개의 이미지로 최신 DNN인 VGG-16 [66](이 논문에서 테스트된 DNN 중 하나)을 훈련시키는 데에는 단일 GTX 1080 Ti GPU에서 최대 7일이 걸릴 수 있습니다.
반면에, 동일한 GPU에서 예측 및 그래디언트 계산은 이미지당 총 약 120밀리초가 소요됩니다.
대규모 DNN의 훈련과 예측 간의 이러한 엄청난 성능 차이는 DeepXplore가 대규모 사전 훈련된 DNN을 테스트하는 데 특히 적합하게 만듭니다.

**Limitations**
DeepXplore는 소프트웨어 분석에서 차분 테스트 기법을 채택하여 차분 테스트의 한계를 상속받습니다.
이러한 한계를 간단히 요약하면 다음과 같습니다.

첫째, 차분 테스트는 동일한 기능을 가진 최소 두 개의 서로 다른 DNN을 필요로 합니다.
또한, 두 DNN이 약간만 다를 경우(즉, 몇 개의 뉴런에 의해), DNN 간에 상당한 차이가 있는 경우보다 DeepXplore가 차이를 유발하는 입력을 찾는 데 더 오래 걸립니다(표 12 참조).
그러나 우리의 평가에 따르면, 대부분의 경우 주어진 문제에 대해 여러 다른 DNN을 쉽게 구할 수 있으며, 개발자들은 종종 맞춤화 및 정확도 향상을 위해 자신의 DNN을 정의하고 훈련합니다.

둘째, 차분 테스트는 적어도 하나의 DNN이 다른 DNN과 다른 결과를 생성할 때만 잘못된 동작을 감지할 수 있습니다.
테스트된 모든 DNN이 동일한 실수를 하면, DeepXplore는 해당 테스트 케이스를 생성할 수 없습니다.
그러나 대부분의 DNN이 독립적으로 구성되고 훈련되기 때문에, 모든 DNN이 동일한 실수를 할 가능성은 낮아 실무에서는 이것이 큰 문제가 되지 않는 것으로 나타났습니다.

## 10. Conclusion
우리는 DL 시스템을 체계적으로 테스트하고 수작업 라벨 없이 잘못된 동작을 자동으로 식별하는 최초의 백박스 시스템인 DeepXplore를 설계하고 구현했습니다.
우리는 입력 집합에 의해 DNN의 몇 가지 규칙이 실행되는지를 측정하는 새로운 지표인 뉴런 커버리지를 도입했습니다.
DeepXplore는 뉴런 커버리지와 잠재적인 잘못된 동작의 수를 모두 극대화하는 공동 최적화 문제를 해결하기 위해 그래디언트 상승을 수행합니다.
DeepXplore는 다섯 개의 실세계 데이터셋에서 훈련된 15개의 최신 DNN에서 수천 개의 잘못된 동작을 발견할 수 있었습니다.
