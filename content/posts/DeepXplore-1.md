+++
title = 'DeepXplore 1'
date = 2024-07-13T11:05:38+09:00
draft = false
+++

이 글은 DeepXplore: Automated Whitebox Testing of Deep Learning Systems (https://arxiv.org/abs/1705.06640)을 번역 및 요약한 글입니다.

## Abstract

딥러닝(DL) 시스템은 자율주행 자동차와 악성 소프트웨어 감지 등 안전 및 보안에 중요한 도메인에 점점 더 많이 배치되고 있으며, 이러한 시스템의 행동이 코너 케이스 입력에 대해 정확하고 예측 가능한 것이 매우 중요합니다.
기존의 DL 테스트는 수작업으로 라벨링 된 데이터에 크게 의존하기 때문에 드문 입력에 대한 잘못된 행동을 드러내지 못하는 경우가 많습니다.

우리는 실제 DL 시스템을 체계적으로 테스트하기 위한 최초의 화이트박스 프레임워크인 DeepXplore을 설계, 구현 및 평가합니다.
첫째, 우리는 테스트 입력이 DL 시스템의 어느 부분을 실행하는지 체계적으로 측정하기 위해 뉴런 커버리지를 도입합니다.
다음으로, 수동 검사를 피하기 위해 유사한 기능을 가진 여러 DL 시스템을 교차 참조 오라클로 활용합니다.
마지막으로, 많은 차별적 행동을 유발하고 높은 뉴런 커버리지를 달성하는 입력을 찾는 방법을 공동 최적화 문제로 나타내고, 이를 그래디언트 기반 탐색 기법을 사용하여 효율적으로 해결할 수 있음을 보여줍니다.

DeepXplore은 최첨단 DL 모델에서 수천 개의 잘못된 코너 행동(예: 가드레일에 충돌하는 자율주행 자동차 및 정상 소프트웨어로 위장한 악성 소프트웨어)을 효율적으로 찾습니다.
테스트된 모든 DL 모델에 대해 DeepXplore은 일반적인 랩탑에서 실행하면서 1초 이내에 잘못된 행동을 나타내는 테스트 입력을 생성했습니다.
또한, DeepXplore가 생성한 테스트 입력을 사용하여 해당 DL 모델을 재학습시켜 모델의 정확도를 최대 3%까지 향상할 수 있음을 보여줍니다.

## 1. Introduction

지난 몇 년 동안 딥러닝(DL)은 이미지 분류, 음성 인식, 게임(예: 바둑) 플레이와 같은 다양한 작업에서 인간 수준의 성능을 달성하거나 이를 능가하는 엄청난 발전을 이루었습니다.
이러한 진전은 자율주행 자동차, 악성 소프트웨어 탐지, 항공기 충돌 회피 시스템과 같은 보안 및 안전에 중요한 시스템에 DL을 널리 채택하고 배치하게 했습니다.

DL 기술의 이러한 광범위한 채택은 예측 가능성과 정확성이라는 중요한 새로운 과제를 제기합니다.
불행히도, DL 시스템은 편향된 훈련 데이터, 모델의 과적합 및 부족과 같은 여러 이유로 코너 케이스에서 예기치 않거나 잘못된 행동을 자주 나타냅니다.
보안 및 안전이 중요한 환경에서 이러한 잘못된 행동은 자율주행 자동차의 치명적인 충돌과 같은 재앙적인 결과를 초래할 수 있습니다.
예를 들어, 구글 자율주행 자동차가 최근에 드문 조건 하에서 버스가 양보할 것으로 예상했지만 그렇지 않아 버스와 충돌했습니다.
테슬라 자동차의 자율주행 시스템은 “밝게 빛나는 하늘과 대비된 흰색”과 “높은 차고”로 인해 트레일러를 장애물로 인식하지 못해 트레일러와 충돌했습니다.
이러한 구석진 경우는 구글이나 테슬라의 테스트 세트에 포함되지 않았기 때문에 테스트 중에 전혀 나타나지 않았습니다.

따라서 전통적인 소프트웨어와 마찬가지로, 보안 및 안전이 중요한 DL 시스템은 다양한 코너 케이스를 체계적으로 테스트하여 잠재적인 결함이나 원치 않는 행동을 이상적으로 발견하고 수정해야 합니다.
이것은 대규모의 실제 DL 시스템을 자동화하고 체계적으로 테스트하는 것은 수천 개의 뉴런과 수백만 개의 매개변수를 가진 DL 시스템의 모든 코너 케이스를 테스트하는 것이 매우 어려운 새로운 시스템 문제라는 것을 제기합니다.

표준적인 DL 시스템 테스트 접근법은 가능한 한 많은 실제 테스트 데이터를 수집하고 수작업으로 라벨링 하는 것입니다.
예를 들어, 구글 자율주행 자동차는 시뮬레이션을 사용하여 합성 훈련 데이터를 생성하기도 합니다.
그러나 이러한 시뮬레이션은 대상 DL 시스템의 내부를 고려하지 않기 때문에 완전히 무작위로 이루어집니다.
따라서 자율주행 자동차의 모든 도로 조건과 같은 실제 DL 시스템의 대규모 입력 공간에서는 이러한 접근법으로 모든 가능한 코너 케이스 중 극히 일부만 다룰 수 있을 뿐입니다.

최근의 적대적 딥러닝 연구는 최소한의 변형을 기존 이미지에 추가하여 최첨단 DL 시스템을 속일 수 있는 신중하게 제작된 합성 이미지를 생성할 수 있음을 보여주었습니다.
핵심 아이디어는 DL 모델이 기존 이미지와 다르게 분류하는 합성 이미지를 생성하는 것이지만, 이러한 이미지는 여전히 인간의 눈에는 동일하게 보입니다.
이러한 적대적 이미지는 DL 모델의 일부 잘못된 행동을 드러내지만, 이 접근법의 주요 제한 사항은 미세한 눈에 보이지 않는 변형으로 제한되거나 수작업 검사를 요구한다는 점입니다.
게다가 기존 DL 테스트의 다른 형태와 마찬가지로 적대적 이미지는 DL 시스템의 논리의 일부(52.3%)만 다룹니다.
본질적으로 현재의 머신러닝 테스트 관행은 낮은 코드 커버리지의 테스트 입력을 사용하여 전통적인 소프트웨어의 버그를 찾는 것과 유사하며, 이는 많은 잘못된 사례를 찾지 못할 가능성이 큽니다.

대규모 DL 시스템의 자동화된 체계적인 테스트의 주요 과제는 두 가지입니다: (1) DL 시스템의 논리의 다른 부분을 트리거하고 다양한 유형의 잘못된 동작을 드러내는 입력을 생성하는 방법, (2) 수동 라벨링/검사 없이 DL 시스템의 잘못된 동작을 식별하는 방법.
이 논문은 두 가지 과제를 해결하기 위해 DeepXplore을 설계하고 구축하는 방법을 설명합니다.

먼저, 우리는 뉴런 커버리지라는 개념을 도입하여 테스트 입력 세트에 의해 활성화된 뉴런의 수를 기준으로 DL 시스템의 논리의 어떤 부분이 실행되었는지를 측정합니다(즉, 출력 값이 임계값보다 높은 뉴런을 의미합니다).
높은 수준에서, DL 시스템의 뉴런 커버리지는 전통적인 시스템의 코드 커버리지와 유사하며, 이는 전통적인 소프트웨어에서 입력에 의해 실행된 코드의 양을 측정하는 표준 경험적 지표입니다.
그러나 전통적인 소프트웨어와 달리 DL 시스템의 대부분의 규칙은 프로그래머가 수동으로 작성한 것이 아니라 훈련 데이터로부터 학습되기 때문에 코드 커버리지 자체는 DL 시스템의 커버리지를 추정하는 데 좋은 지표가 아닙니다.
실제로 우리가 테스트한 대부분의 DL 시스템에 대해 단일 무작위로 선택된 테스트 입력만으로도 100% 코드 커버리지를 달성할 수 있었지만, 뉴런 커버리지는 10% 미만이었습니다.

다음으로, 유사한 기능을 가진 여러 DL 시스템(예: 구글, 테슬라, GM의 자율주행 자동차)을 교차 참조 오라클로 사용하여 수동 검증 없이 잘못된 구석진 경우를 식별하는 방법을 보여줍니다.
예를 들어, 동일한 입력에 대해 한 자율주행 자동차가 좌회전을 결정하고 다른 자동차들이 우회전을 결정한다면, 그중 하나는 잘못된 것일 가능성이 큽니다.
이러한 차이 테스트 기법은 과거에 다양한 전통적인 소프트웨어에서 수동 명세 없이 논리 버그를 감지하는 데 성공적으로 적용되었습니다.
이 논문에서는 차이 테스트가 DL 시스템에 어떻게 적용될 수 있는지 보여줍니다.

마지막으로, DL 시스템의 뉴런 커버리지를 최대화하면서 가능한 한 많은 차별적 동작(즉, 유사한 여러 DL 시스템 간의 차이)을 드러내는 테스트 입력을 생성하는 문제를 공동 최적화 문제로 형성하는 방법을 보여줍니다.
전통적인 프로그램과 달리, DL 시스템에서 사용되는 대부분의 인기 있는 심층 신경망(DNN)이 근사하는 함수는 미분 가능하므로, 해당 모델에 대한 화이트박스 접근이 주어지면 입력에 대한 기울기를 정확하게 계산할 수 있습니다.
이 논문에서는 이러한 기울기를 사용하여 대규모 실제 DL 시스템에 대해 앞서 언급한 공동 최적화 문제를 효율적으로 해결하는 방법을 보여줍니다.

우리는 대규모 DL 시스템을 위한 최초의 효율적인 화이트박스 테스트 프레임워크인 DeepXplore을 설계, 구현 및 평가합니다.
우리의 지식에 따르면 이는 최초입니다.
DeepXplore은 뉴런 커버리지와 DL 시스템 간의 행동 차이를 최대화할 뿐만 아니라, 사용자 정의 제약 조건을 추가하여 다양한 유형의 현실적인 입력(예: 이미지/비디오의 다양한 조명 및 가림 현상)을 시뮬레이션하는 것도 지원합니다.
우리는 DeepXplore가 Udacity 자율주행 자동차 챌린지 데이터, ImageNet과 MNIST의 이미지 데이터, Drebin의 안드로이드 악성 소프트웨어 데이터, Contagio/VirusTotal의 PDF 악성 소프트웨어 데이터를 포함한 5개의 실제 데이터셋을 사용하여 훈련된 15개의 최첨단 DL 모델에서 수천 개의 고유한 잘못된 코너 케이스(예: 가드레일에 충돌하는 자율주행 자동차)를 효율적으로 찾아낸다는 것을 입증합니다.
테스트된 모든 DL 모델에 대해, DeepXplore는 평균적으로 일반적인 노트북에서 실행되면서 1초 이내에 잘못된 행동을 나타내는 하나의 테스트 입력을 생성했습니다.
DeepXplore가 생성한 입력은 동일한 수의 무작위 선택 입력과 적대적 입력보다 평균적으로 각각 34.4%와 33.2% 더 높은 뉴런 커버리지를 달성했습니다.
또한, DeepXplore가 생성한 테스트 입력을 사용하여 해당 DL 모델을 재학습시켜 분류 정확도를 향상하고 잠재적으로 오염된 훈련 데이터를 식별할 수 있음을 보여줍니다.
우리는 DeepXplore가 생성한 입력을 사용하여 DL 모델을 재학습시킴으로써 동일한 수의 무작위 또는 적대적 입력을 사용한 재학습에 비해 분류 정확도가 최대 3% 향상됨을 달성합니다.

우리의 주요 기여는 다음과 같습니다:

* 우리는 테스트 입력 세트에 의해 탐색된 DL 논리의 양을 추정할 수 있는 DL 시스템을 위한 최초의 화이트박스 테스트 메트릭으로 뉴런 커버리지를 도입했습니다.
* 우리는 뉴런 커버리지를 최대화하면서 유사한 DL 시스템 간의 많은 행동 차이를 찾는 문제가 공동 최적화 문제로 형성될 수 있음을 입증했습니다. 이 문제를 효율적으로 해결하기 위한 그래디언트 기반 알고리즘을 제시합니다.
* 우리는 이러한 모든 기술을 DeepXplore의 일환으로 구현했습니다. 이는 5개의 인기 있는 데이터셋에서 총 132,057개의 뉴런을 가진 15개의 최첨단 DL 모델에서 수천 개의 잘못된 코너 케이스(예: 그림 1에 나타난 가드레일에 충돌하는 자율주행 자동차)를 드러낸 최초의 화이트박스 DL 테스트 프레임워크입니다.
* 우리는 DeepXplore가 생성한 테스트가 해당 DL 시스템을 재학습시켜 분류 정확도를 최대 3% 향상시킬 수 있음을 보여줍니다.

![Figure 1](/posts/DeepXplore/figure1.png)

## 2. Background
### 2.1 DL Systems
우리는 DL 시스템을 최소 하나의 딥 뉴럴 네트워크(DNN) 구성 요소를 포함하는 모든 소프트웨어 시스템으로 정의합니다.
일부 DL 시스템은 DNN으로만 구성될 수 있습니다(예: 수동 규칙 없이 조향각을 예측하는 자율주행 자동차의 DNN).
반면에 다른 시스템은 최종 출력을 생성하기 위해 DNN 구성 요소와 다른 전통적인 소프트웨어 구성 요소가 상호 작용할 수 있습니다.

DL 시스템의 DNN 구성 요소의 개발 과정은 전통적인 소프트웨어 개발과 근본적으로 다릅니다.
전통적인 소프트웨어에서는 개발자가 시스템의 논리를 직접 지정하는 반면, DNN 구성 요소는 데이터를 통해 자동으로 규칙을 학습합니다.
DNN 구성 요소의 개발자는 그림 2에서 보이는 것처럼 훈련 데이터, 특징 및 모델의 구조적 세부 사항(예: 레이어 수)을 수정하여 DNN이 학습하는 규칙에 간접적으로 영향을 미칠 수 있습니다.

DNN의 규칙은 대부분 개발자에게도 알려져 있지 않기 때문에, 안전이 중요한 환경에서는 DNN의 잘못된 동작을 테스트하고 수정하는 것이 중요합니다.
이 논문에서는 주로 DL 시스템에서 잘못된 동작을 유발하는 입력을 자동으로 찾는 데 초점을 맞추고, 이러한 입력을 사용하여 훈련 데이터를 보강하거나 필터링하여 버그가 있는 동작을 수정하는 방법에 대한 예비 증거를 § 7.3에서 제공합니다.

![Figure 2](/posts/DeepXplore/figure2.png)

### 2.2 DNN Architecture
DNN은 수백만 개의 상호 연결된 뉴런을 가진 인간의 뇌에서 영감을 받았습니다.
DNN은 라벨링 된 훈련 데이터를 제외한 인간의 지침 없이도 원시 입력에서 관련된 고수준의 특징을 자동으로 식별하고 추출하는 놀라운 능력으로 알려져 있습니다.
최근 몇 년 동안 DNN은 대규모 데이터셋의 증가, 전문화된 하드웨어, 효율적인 훈련 알고리즘 덕분에 많은 응용 도메인에서 인간의 성능을 능가했습니다.

DNN은 그림 3에서 볼 수 있듯이 여러 개의 층으로 구성되며, 각 층에는 여러 개의 뉴런이 포함됩니다.
뉴런은 DNN 내부의 개별 계산 단위로, 입력에 활성화 함수를 적용하고 그 결과를 다른 연결된 뉴런에게 전달합니다(그림 3 참조).
일반적인 활성화 함수에는 시그모이드, 쌍곡선 탄젠트, 또는 ReLU(정류 선형 유닛) 등이 있습니다.
DNN은 보통 최소한 세 개의 층(입력층, 출력층, 하나 이상의 은닉층)을 가집니다.
한 층의 각 뉴런은 다음 층의 뉴런과 직접 연결됩니다.
각 층의 뉴런 수와 그 사이의 연결은 DNN마다 크게 다를 수 있습니다.
전체적으로 DNN은 수많은 파라메트릭 하위 함수로 구성된 다중 입력, 다중 출력 파라메트릭 함수 F로 수학적으로 정의될 수 있습니다.

![Figure 3](/posts/DeepXplore/figure3.png)

DNN에서 뉴런 간의 각 연결은 뉴런 간 연결의 강도를 특징짓는 가중치 매개변수에 묶여 있습니다.
지도 학습의 경우, 연결의 가중치는 훈련 데이터를 사용하여 비용 함수를 최소화함으로써 훈련 중에 학습됩니다.
DNN은 다양한 훈련 알고리즘을 사용하여 훈련될 수 있지만, 역전파를 사용하는 경사 하강법이 DNN에서 가장 인기 있는 훈련 알고리즘입니다.

네트워크의 각 층은 입력에 포함된 정보를 더 높은 수준의 데이터 표현으로 변환합니다.
예를 들어, 그림 4b에 나와 있는 미리 훈련된 네트워크가 이미지를 두 가지 범주로 분류하는 경우를 생각해 보십시오: 인간 얼굴과 자동차. 처음 몇 개의 은닉층은 원시 픽셀 값을 가장자리나 색상과 같은 저수준의 텍스처 특징으로 변환하고, 이를 더 깊은 층으로 전달합니다.
마지막 몇 개의 층은 코, 눈, 바퀴, 헤드라이트와 같은 의미 있는 고수준의 추상화를 추출하고 조립하여 분류 결정을 내립니다.

![Figure 4](/posts/DeepXplore/figure4.png)

### 2.3 Limitations of Existing DNN Testing
**비용이 많이 드는 라벨링 작업**
기존의 DNN 테스트 기법은 목표 작업(예: 자율주행, 이미지 분류, 악성 소프트웨어 탐지)에 대해 올바른 라벨/행동을 제공하기 위해 매우 많은 인적 노력이 필요합니다. 복잡하고 고차원적인 실제 입력에 대해 사람들, 심지어 도메인 전문가도 큰 데이터셋에 대해 작업을 효율적으로 수행하는 데 어려움을 겪습니다.
예를 들어, 잠재적으로 악성 실행 파일을 식별하도록 설계된 DNN을 생각해 보십시오.
보안 전문가라도 실행 파일을 실행해보지 않고는 악성인지 정상인지 판단하는 데 어려움을 겪을 수 있습니다.
그러나 샌드박스 내에서 악성 소프트웨어를 실행하고 모니터링하는 것은 상당한 성능 오버헤드를 발생시키므로, 수동 라벨링이 많은 입력에 대해 확장되기 어렵게 만듭니다.

**낮은 테스트 커버리지**
기존의 DNN 테스트 기법 중 어느 것도 DNN의 다양한 규칙을 커버하려고 시도하지 않습니다.
따라서 테스트 입력은 종종 DNN의 다양한 잘못된 동작을 발견하지 못합니다.

예를 들어, DNN은 전체 데이터셋을 두 개의 무작위 부분으로 나누어 하나는 훈련용으로, 다른 하나는 테스트용으로 사용하는 방식으로 자주 테스트됩니다.
이러한 경우 테스트 세트는 DNN이 학습한 모든 규칙의 작은 부분만 실행할 수 있습니다.
DNN을 대상으로 하는 최근의 적대적 회피 공격 결과는 DNN 기반 이미지 분류기(무작위로 선택된 테스트 세트에서 최첨단 성능을 자랑하는)가 테스트 이미지에 인간이 인지할 수 없는 작은 변형을 추가하여 생성된 합성 이미지를 여전히 잘못 분류하는 코너 케이스가 존재함을 보여주었습니다.
그러나 적대적 입력은 무작위 테스트 입력과 마찬가지로 DNN이 학습한 규칙의 작은 부분만 커버합니다.
이는 커버리지를 최대화하도록 설계되지 않았기 때문입니다.
게다가, 이러한 입력은 테스트 입력 주위의 작은 눈에 띄지 않는 변형으로 본질적으로 제한되며, 더 큰 변형은 입력의 시각적 변화를 초래하므로 DNN의 결정의 정확성을 보장하기 위해 수동 검사가 필요합니다.

**낮은 커버리지 DNN 테스트의 문제**
DNN이 학습한 규칙의 낮은 테스트 커버리지 문제를 더 잘 이해하기 위해 전통적인 소프트웨어 테스트에서의 유사한 문제에 대한 비유를 제공합니다.
그림 4는 전통적인 프로그램과 DNN이 입력을 처리하고 출력을 생성하는 방식을 나란히 비교한 것입니다.
특히, 이 그림은 전통적인 소프트웨어와 DNN의 유사성을 보여줍니다: 소프트웨어 프로그램에서 각 문장은 이전 문장(들)의 출력을 다음 문장(들)의 입력으로 변환하는 특정 작업을 수행하는 반면, DNN에서는 각 뉴런이 이전 뉴런(들)의 출력을 다음 뉴런(들)의 입력으로 변환합니다.
물론, 전통적인 소프트웨어와 달리 DNN은 명시적인 분기(branch)가 없지만, 뉴런의 출력 값이 낮아질수록 하류 뉴런에 대한 뉴런의 영향력이 감소합니다.
출력 값이 낮을수록 영향력이 적어지며, 반대의 경우도 마찬가지입니다. 뉴런의 출력 값이 0이 되면, 해당 뉴런은 하류 뉴런에 아무런 영향도 미치지 않습니다.

그림 4a에서 보여주듯이, 전통적인 소프트웨어 테스트에서의 낮은 커버리지 문제는 명백합니다.
이 경우, 테스트 입력이 0xdeadbeef이 아니면 버그 있는 동작이 절대 나타나지 않습니다.
무작위로 그러한 값을 선택할 가능성은 매우 적습니다.
마찬가지로, 낮은 커버리지 테스트 입력은 DNN의 다양한 동작을 탐색하지 못하게 합니다.
예를 들어, 그림 4b에 나와 있는 것처럼 이미지를 입력으로 받아 두 개의 다른 클래스로 분류하는 단순화된 신경망을 생각해 보십시오: 자동차와 얼굴. 각 뉴런(노드로 표시됨) 내의 텍스트는 뉴런이 감지하는 객체 또는 속성을 나타내며, 각 뉴런 내의 숫자는 해당 뉴런이 출력하는 실제 값을 나타냅니다.
이 숫자는 뉴런이 출력에 대해 얼마나 확신하는지를 나타냅니다.
무작위로 선택된 입력이 뉴런의 예상치 못한 조합에 대해 높은 출력 값을 설정할 가능성은 매우 낮습니다.
따라서 많은 잘못된 DNN 동작은 무작위 테스트를 많이 수행하더라도 탐색되지 않은 상태로 남아 있을 것입니다.
예를 들어, 이미지가 "코(Nose)"와 "빨강(Red)"으로 라벨이 지정된 뉴런들이 높은 출력 값을 생성하게 하고, DNN이 입력 이미지를 자동차로 잘못 분류하는 경우, 빨간 코를 가진 이미지(예: 광대 사진)의 가능성이 매우 적기 때문에 이러한 동작은 정기적인 테스트 중에는 절대 발견되지 않을 것입니다.
